# üìã Zusammenfassung

Wir stellen **Blind Multi-Agent Synthesis (BMAS)** vor, eine Methodik zur Messung von Konvergenz und Divergenz mehrerer gro√üer Sprachmodelle (LLMs), die auf identische Prompts unter strikter gegenseitiger Isolation antworten. Inspiriert von der Delphi-Methode aus der Expertenprognose erzwingt BMAS eine vollst√§ndige Antwortisolation pro Modell: Kein Modell kennt die Ausgabe eines anderen Modells, bevor die Synthesephase beginnt.

Wir evaluieren zw√∂lf modernste LLMs √ºber drei Dom√§nenebenen: (A) hochpr√§zise technische Fragen mit verifizierbaren Korrektantworten, (B) regulatorische und Compliance-Fragen mit autoritativen Rechtsquellen sowie (C) strategische und architekturelle Fragen mit legitimen Expertenmeinungsverschiedenheiten. Mithilfe semantischer √Ñhnlichkeitsmetriken (BERTScore, Kosinus-Embedding-Distanz), faktischer Genauigkeit gegen vorregistrierte Korrektantworten und Ausrei√üererkennung via DBSCAN-Clustering quantifizieren wir die modell√ºbergreifende Abweichung sowie deren Zusammenhang mit Dom√§nentyp und Halluzinationsrate.

Unsere zentrale Hypothese lautet: In gut definierten, faktischen Dom√§nen konvergieren LLM-Antworten so stark, dass **Konsens als Qualit√§tssignal** dient. Hohe modell√ºbergreifende √úbereinstimmung ist ein Pr√§diktor f√ºr faktische Korrektheit, w√§hrend signifikante Divergenz auf Modellhalluzinationen oder unzureichend spezifizierte Fragen hinweist. Zus√§tzlich evaluieren wir drei Synthesestrategien - Mehrheitsvotum auf Behauptungsebene, semantische Zentroidselektion und LLM-as-Judge-Synthese - anhand vorregistrierter Korrektantworten.

BMAS hat direkte praktische Implikationen f√ºr KI-Eins√§tze in Hochrisikobereichen wie Beh√∂rden, Gesundheitswesen und Rechtssystemen, in denen keiner einzelnen Modellausgabe bedingungslos vertraut werden kann. Indem BMAS **Divergenz als Anomaliesignal** statt als Koordinationsversagen behandelt, bietet es eine praktische Qualit√§tssicherungsschicht f√ºr LLM-Systeme im Produktivbetrieb.

**Schlagw√∂rter:** Gro√üe Sprachmodelle, Multi-Agenten-Systeme, Konsens, Halluzinationserkennung, Delphi-Methode, semantische √Ñhnlichkeit, KI-Qualit√§tssicherung
