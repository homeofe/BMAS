# üí° 7. Diskussion

## 7.1 Interpretation von Konvergenz und Divergenz

Die zentrale Behauptung von BMAS ist, dass modell√ºbergreifende Konvergenz informativ ist - nicht nur als statistische Eigenschaft des Experiments, sondern als praktisches Signal f√ºr nachgelagerte Anwendungen. Unsere Ergebnisse [siehe Abschnitt 4] st√ºtzen diese Behauptung f√ºr faktische Dom√§nen und enth√ºllen dabei wichtige Nuancen.

Hohe Konvergenz in den Dom√§nen A und B validiert die Intuition, dass gut kalibrierte Modelle, die auf denselben autoritativen Quellen trainiert wurden, bei eindeutigen Fragen zur selben korrekten Antwort tendieren. Dies ist kein triviales Ergebnis: Es legt nahe, dass f√ºr Compliance-Verifikation, regulatorische Interpretation und technische Standardzitation ein Konsens mehrerer unabh√§ngiger Modelle eine einzelne Expertenpr√ºfung ersetzen - oder zumindest erg√§nzen - kann, wenn Zeitdruck herrscht.

Geringe Konvergenz in Dom√§ne C (strategische und mehrdeutige Prompts) ist gleicherma√üen informativ. Statt ein Modellversagen darzustellen, spiegelt sie die genuine epistemische Schwierigkeit der Fragen wider. Wenn zw√∂lf unabh√§ngige Expertensysteme bei optimalen Architekturentscheidungen oder Sicherheitsinvestitionsabw√§gungen uneins sind, ist die Uneinigkeit selbst bedeutsam - sie signalisiert, dass die Frage keine dominante richtige Antwort hat und menschliche Deliberation verdient. BMAS dient damit als **Komplexit√§tsorakel** zus√§tzlich zu einem Qualit√§tssignal.

## 7.2 Der Divergenz-Halluzinations-Zusammenhang

Unsere Ausrei√üeranalyse [siehe Abschnitt 5] liefert erste Evidenz f√ºr die Divergenz-als-Signal-Hypothese. Modelle, die im Embedding-Raum als Ausrei√üer bewertet werden, tendieren zu niedrigeren faktischen Genauigkeitsscores, was darauf hindeutet, dass semantische Isolation vom Konsensclustern mit faktischer Abweichung von der Korrektantwort korreliert.

Dieses Ergebnis hat praktische Implikationen f√ºr den KI-Einsatz in regulierten Branchen. Ein Produktionssystem, das BMAS-artige √úberwachung implementiert, k√∂nnte Antworten, die signifikant vom Konsensclustern abweichen, zur menschlichen Pr√ºfung flaggen und so die Abh√§ngigkeit von manueller Verifikation jeder Modellausgabe reduzieren, w√§hrend Genauigkeitsgarantien erhalten bleiben.

Wir warnen jedoch, dass Korrelation nicht Kausalit√§t ist. Eine Ausrei√üerantwort kann korrekt sein, w√§hrend der Konsens falsch liegt - besonders bei k√ºrzlich ver√∂ffentlichten Informationen oder dom√§nenspezifischem Wissen, das in den Trainingsdaten der meisten Modelle nicht gut repr√§sentiert ist. Die M1-Antwort auf A01 (CVE-2024-21762 CVSS-Scoring) demonstrierte dies: Der Ausrei√üer-Score war mathematisch korrekt, w√§hrend der Konsens beim herstellergenannten Score konvergierte, der aufgrund einer Rundungskonvention abweicht. Jede Produktionsimplementierung von divergenzbasierter Filterung muss eine menschliche Override-F√§higkeit erhalten.

## 7.3 Vergleich der Synthesestrategien

Die drei evaluierten Synthesestrategien - Mehrheitsvotum (S1), semantischer Zentroid (S2) und LLM-as-Judge (S3) - weisen jeweils unterschiedliche Kompromisse auf [siehe Abschnitt 6].

S1 (Mehrheitsvotum) erzeugt umfassende Abdeckung, kann aber ausf√ºhrlich sein und gelegentlich Minderheitsbehauptungen mit geringer Konfidenz trotz der 60%-Schwelle einschlie√üen. Es ist am besten geeignet, wenn Vollst√§ndigkeit vor Pr√§gnanz priorisiert wird.

S2 (semantischer Zentroid) erzeugt zuverl√§ssig die "durchschnittlichste" Antwort - informativ als Benchmark, aber m√∂glicherweise wichtige Minderheitseinsichten verbergend. Es eignet sich am besten, wenn eine repr√§sentative einzelne Antwort ben√∂tigt wird und die Frage gut definiert ist.

S3 (LLM-as-Judge) erzeugt die h√∂chste faktische Genauigkeit f√ºr Dom√§nen A und B [siehe Abschnitt 6], f√ºhrt aber eine neue Abh√§ngigkeit ein - die eigenen Verzerrungen des Richtermodells. Wenn das Richtermodell selbst bei einem gegebenen Prompt ein Ausrei√üer ist, kann seine Synthese die Mehrheitsmeinung systematisch unterrepr√§sentieren. Die Verwendung eines zur√ºckgehaltenen Modells (eines, das nicht am blinden Lauf teilgenommen hat) als Richter mildert dieses Risiko.

## ‚ö†Ô∏è 7.4 Einschr√§nkungen

**Stichprobengr√∂√üe.** Mit 45 Prompts √ºber drei Dom√§nen etabliert diese Studie erste Evidenz f√ºr die BMAS-Methodik, erlaubt aber keine breite statistische Verallgemeinerung. Eine Folgestudie mit 100+ Prompts pro Dom√§ne w√ºrde die Behauptungen substanziell st√§rken.

**Modellauswahl.** Die f√ºnf verwendeten Modelle stellen eine Opportunit√§tsstichprobe zug√§nglicher Frontier-Modelle zum Zeitpunkt der Studie dar. Die Modellzusammensetzung beeinflusst die Konsensverteilung: Eine Studie mit zw√∂lf Anthropic-Modellen w√ºrde andere Varianzeigenschaften zeigen als eine anbieter√ºbergreifende Studie. Zuk√ºnftige Arbeiten sollten die Modellzusammensetzung systematisch variieren.

**Korrektantwortqualit√§t.** Die Korrektantworten f√ºr Dom√§nen A und B wurden durch Web-Recherche gegen prim√§re Quellen zusammengestellt. Drei Eintr√§ge wurden als manuell verifikationsbed√ºrftig markiert (A01 CVSS-Diskrepanz, A10 BSI-Quellenaccess, B09 EDPB-Leitlinienreferenz). Diese Eintr√§ge werden im Datensatz vermerkt, k√∂nnen aber geringf√ºgige Scoring-Ungenauigkeiten einbringen.

**Zeitliche G√ºltigkeit.** LLM-Wissensstand und Modellversionen √§ndern sich. Die hier berichteten Ergebnisse spiegeln spezifische Modellversionen zu einem bestimmten Zeitpunkt wider. Replikationsstudien sollten Modellversion und Wissensstand pr√§zise dokumentieren.

**Temperatur und Sampling.** Wir haben die Temperatur nicht √ºber Modelle hinweg kontrolliert. Das Standard-Sampling-Verhalten wurde beibehalten, um nat√ºrliche Modellvarianz zu erfassen. Das bedeutet, dass ein Teil der beobachteten Varianz auf Dekodierungszuf√§lligkeit zur√ºckzuf√ºhren sein kann statt auf echte Wissensunterschiede. Kontrollierte Temperatur-Replikation w√ºrde diese Variable isolieren.

**Token-L√§nge ist keine Informationsdichte.** Unsere Beobachtung, dass M4 (Gemini 2.5-pro) konsistent mehr Tokens produziert, impliziert nicht gr√∂√üere Genauigkeit oder Vollst√§ndigkeit. Token-Anzahl ist ein stilistisches Signal, kein Qualit√§tssignal. Alle faktischen Genauigkeitsbehauptungen basieren auf Korrektantwort-Scoring, nicht auf Antwortl√§nge.

## 7.5 Implikationen f√ºr den KI-Einsatz

BMAS hat drei direkte Implikationen f√ºr den Einsatz:

**1. Konsens als Qualit√§tstor.** In hochrisikobehafteten KI-Systemen (Recht, Medizin, Beh√∂rden) kann eine BMAS-artige Schicht mehrere Modelle auf dieselbe Anfrage ausf√ºhren und die Antwort zur√ºckhalten, bis der Konsens einen definierten Schwellenwert erreicht. Uneinigkeit l√∂st menschliche Pr√ºfung aus statt automatisierter Aktion.

**2. Dom√§nen-Routing.** BMAS-Ergebnisse legen nahe, dass f√ºr faktische Anfragen mit autoritativen Quellen ein einzelnes leistungsstarkes Modell ausreichen kann. Der Multi-Modell-Overhead ist am st√§rksten f√ºr strategische, mehrdeutige oder neuartige Anfragen gerechtfertigt, bei denen der Dom√§ne eine einzelne autoritative Korrektantwort fehlt.

**3. Diversit√§tsanforderungen.** BMAS-Leistung h√§ngt von Modellvielfalt ab. Zwei sehr √§hnliche Modelle desselben Anbieters liefern weniger Informationen als zwei Modelle verschiedener Architekturfamilien. Beschaffungsentscheidungen f√ºr KI-Systeme in regulierten Branchen sollten Anbietervielfalt neben individueller Modellkapazit√§t ber√ºcksichtigen.

## 7.6 Zuk√ºnftige Arbeiten

Mehrere Erweiterungen des BMAS-Frameworks verdienen Untersuchung:

- **Temporale Drift-Studie:** Ausf√ºhren derselben Prompts gegen dieselben Modelle in 6-Monats-Intervallen, um zu messen, ob sich Konvergenz bei Modellaktualisierungen √§ndert
- **Dom√§nenerweiterung:** Ausweitung auf medizinische Diagnostik, Finanzanalyse und juristische Argumentation
- **Kalibrierungsanalyse:** Messen, ob Modellkonfidenz (wenn ausgedr√ºckt) mit Konsens√ºbereinstimmung korreliert
- **Adaptive Synthese:** Entwicklung einer Synthesestrategie, die S1, S2 oder S3 dynamisch basierend auf gemessener Konvergenz ausw√§hlt
- **Menschliche Evaluation:** Vergleich der BMAS-Synthesequalit√§t mit menschlichen Expertenantworten mittels Blindevaluation
