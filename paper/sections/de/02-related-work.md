# 2. Verwandte Arbeiten

BMAS baut auf strukturierten Expertenkonsens-Methoden, Multi-Sample- und Multi-Modell-LLM-Techniken, automatisierten Evaluationsmetriken und dichtebasiertem Clustering auf. Dieser Abschnitt bespricht jeden Bereich und erläutert die Beziehung von BMAS zu früheren Arbeiten.

## 2.1 Die Delphi-Methode

Dalkey und Helmer (1963) entwickelten die Delphi-Methode bei der RAND Corporation als strukturierten Ansatz zur Expertenprognose. Im ursprünglichen Protokoll gaben Expertengremien unabhängig voneinander Schätzungen ab, ohne die Antworten der anderen zu kennen, und ein Moderator aggregierte die Ergebnisse über mehrere iterative Runden. Die zentrale Stärke der Methode besteht darin, dass Isolation Verankerungseffekte und Gruppendenken verhindert und echte Meinungsverschiedenheiten sichtbar macht, bevor Konsens angestrebt wird. BMAS übernimmt dieses Isolationsprinzip direkt: Jedes LLM antwortet auf Prompts, ohne die Ausgaben anderer Modelle zu kennen, sodass Konvergenz, wenn sie auftritt, unabhängiges Denken widerspiegelt und keine Imitation.

## 2.2 Self-Consistency

Wang et al. (2022) schlugen Self-Consistency als Dekodierungsstrategie vor, die mehrere Reasoning-Ketten aus einem einzelnen Sprachmodell sampelt und die endgültige Antwort per Mehrheitsvoting bestimmt. Diese Methode zeigte signifikante Verbesserungen bei arithmetischen und Common-Sense-Reasoning-Benchmarks durch die Ausnutzung der Intuition, dass korrekte Reasoning-Pfade wahrscheinlicher zur selben Antwort konvergieren als falsche. Da jedoch alle Reasoning-Ketten aus demselben Modell stammen, erfasst Self-Consistency nur die intramodale Dekodierungsvarianz, nicht die tieferen Unterschiede in Trainingsdaten, Architektur und Ausrichtung, die verschiedene Anbieter unterscheiden. BMAS erweitert die Konvergenz-als-Qualitätssignal-Intuition auf den anbieterübergreifenden Rahmen, in dem Übereinstimmung zwischen unabhängig trainierten Modellen ein stärkeres Prior für Korrektheit darstellt.

## 2.3 Mixture of Agents

Wang et al. (2024) führten das Mixture-of-Agents (MoA)-Framework ein, in dem mehrere LLMs an iterativen Aggregationsrunden teilnehmen, bei denen jedes Modell die Ausgaben der anderen beobachten und verfeinern kann. MoA demonstrierte, dass kollaborative Verbesserung über Modelle hinweg die Leistung auf Benchmarks wie AlpacaEval und MT-Bench steigerte und Scores erzielte, die mit Frontier-Modellen vergleichbar sind. Der entscheidende Unterschied zu BMAS besteht darin, dass MoA nicht blind ist: Modelle in späteren Runden sehen frühere Ausgaben, was das Risiko der Fehlerfortpflanzung birgt - eine selbstsichere Halluzination in einer frühen Runde kann nachfolgende Modelle beeinflussen und legitimen Widerspruch unterdrücken. BMAS vermeidet dies bewusst durch strikte Isolation während der Antwortphase und verschiebt jede modellübergreifende Interaktion auf eine separate Synthesephase.

## 2.4 LLM-as-Judge

Zheng et al. (2023) untersuchten den Einsatz großer Sprachmodelle als Evaluatoren anderer Modellausgaben und führten die MT-Bench- und Chatbot-Arena-Benchmarks ein. Ihre Arbeit zeigte, dass starke LLMs als skalierbare Proxys für menschliche Evaluation dienen können und hohe Übereinstimmung mit Expertengutachtern bei paarweisen Präferenzurteilen erzielten. In BMAS ist die Richterrolle dagegen auf eine von drei Synthesestrategien beschränkt (S3): Ein sechstes Modell synthetisiert die fünf blinden Antworten zu einer einzigen Ausgabe, aber Korrektheit wird letztlich anhand vorregistrierter Korrektantworten gemessen, nicht anhand der Präferenzen des Richters.

## 2.5 BERTScore

Zhang et al. (2020) schlugen BERTScore vor, eine automatische Evaluationsmetrik, die token-level-Ähnlichkeit zwischen Kandidaten- und Referenztexten mithilfe kontextueller Embeddings von vortrainierten Transformermodellen berechnet. Im Gegensatz zu N-Gramm-Überlappungsmetriken wie BLEU oder ROUGE erfasst BERTScore semantische Äquivalenz über verschiedene Oberflächenformen hinweg und ist robust gegenüber Paraphrasierungen. BMAS übernimmt BERTScore F1 als primäre paarweise Ähnlichkeitsmetrik zur Messung modellübergreifender Konvergenz, ergänzt durch Kosinus-Ähnlichkeit auf Satz-Embedding-Ebene für rechnerische Effizienz.

## 2.6 Constitutional AI

Bai et al. (2022) führten Constitutional AI (CAI) bei Anthropic ein, eine Trainingsmethodik, bei der ein Modell seine eigenen Ausgaben gemäß einem Satz von Prinzipien (einer "Verfassung") kritisiert und überarbeitet, bevor Reinforcement Learning aus menschlichem Feedback eingesetzt wird. CAI zeigte, dass Selbstkritik schädliche Ausgaben reduzieren kann, während Nützlichkeit erhalten bleibt. Dies stellt einen Einzelmodell-Ansatz zur Qualitätsverbesserung durch iterative Verbesserung dar. BMAS kann als Erweiterung dieser Kritik-und-Überarbeitung-Intuition vom Einzelmodell-Loop auf einen Multi-Modell-, Multi-Anbieter-Rahmen betrachtet werden: Statt eines Modells, das sich selbst bewertet, dienen mehrere unabhängig trainierte Modelle durch das Divergenzsignal als implizite Kritiker füreinander.

## 2.7 DBSCAN

Ester et al. (1996) schlugen DBSCAN (Density-Based Spatial Clustering of Applications with Noise) vor, einen Clustering-Algorithmus, der Datenpunkte auf Basis von Dichtekonnektivität gruppiert und Punkte in Niedrigdichtebereichen als Rauschen oder Ausreißer identifiziert. Im Gegensatz zu k-Means erfordert DBSCAN keine a-priori-Festlegung der Clusteranzahl und verarbeitet natürlich unregelmäßig geformte Cluster. BMAS setzt DBSCAN auf dem Embedding-Raum von Modellantworten ein, um Ausreißerausgaben zu erkennen: In faktischen Domänen wird eine Ausreißerantwort - eine, die außerhalb der Epsilon-Nachbarschaft des Konsensclusters liegt - als potenzielle Halluzination behandelt, während Ausreißer in strategischen Domänen legitime Minderheitsansichten darstellen können.

## 2.8 Positionierung

BMAS ist nach unserem Kenntnisstand das erste Framework, das vier Eigenschaften kombiniert, die in keinem einzelnen früheren Ansatz zusammen vorhanden sind. Erstens erzwingt es anbieterübergreifende Blind-Isolation: Im Gegensatz zu Self-Consistency, das aus einem Modell sampelt, sammelt BMAS Antworten von unabhängig trainierten Modellen verschiedener Anbieter und erfasst Variation in Trainingsdaten, Architektur und Ausrichtung statt nur Dekodierungsstochastizität. Zweitens führt es domänenstratifizierte Analyse ein und unterteilt Prompts in faktische, regulatorische und strategische Strata, um zu testen, ob Konvergenzmuster domänenabhängig sind - eine Dimension, die von MoA oder LLM-as-Judge-Evaluationen nicht untersucht wurde. Drittens behandelt es Divergenz als Anomaliesignal statt als Koordinationsversagen: Hohe modellübergreifende Uneinigkeit in gut definierten Domänen wird als Prädiktor für faktische Fehler hypothetisiert und verwandelt Uneinigkeit von einer Störgröße in ein Diagnosewerkzeug. Viertens bietet es einen kontrollierten Vergleich von Synthesestrategien (Mehrheitsvotum, semantischer Zentroid und LLM-as-Judge), evaluiert anhand vorregistrierter Korrektantworten, und liefert empirische Orientierung zur bestmöglichen Aggregation unabhängiger Modellausgaben in der Praxis.
