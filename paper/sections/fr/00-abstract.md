# üìã R√©sum√©

Nous introduisons **Blind Multi-Agent Synthesis (BMAS)**, une m√©thodologie pour mesurer la convergence et la divergence de plusieurs grands mod√®les de langage (LLMs) r√©pondant √† des prompts identiques dans une isolation stricte. Inspir√© par la m√©thode Delphi en pr√©vision d'experts, BMAS impose une isolation compl√®te des r√©ponses par mod√®le : aucun mod√®le n'observe la sortie d'un autre mod√®le avant la phase de synth√®se.

Nous √©valuons douze LLMs de pointe sur trois strates de domaines : (A) des questions techniques de haute pr√©cision avec des r√©ponses v√©rifiables, (B) des questions r√©glementaires et de conformit√© avec des sources juridiques faisant autorit√©, et (C) des questions strat√©giques et architecturales avec des d√©saccords l√©gitimes entre experts. En utilisant des m√©triques de similarit√© s√©mantique (BERTScore, distance cosinus sur embeddings), la pr√©cision factuelle compar√©e √† des r√©ponses de r√©f√©rence pr√©-enregistr√©es, et la d√©tection de valeurs aberrantes via le clustering DBSCAN, nous quantifions la d√©viation inter-mod√®les et sa relation avec le type de domaine et le taux d'hallucination.

Notre hypoth√®se centrale est que dans les domaines factuels bien contraints, les r√©ponses des LLMs convergent suffisamment pour que le **consensus serve de signal de qualit√©** : un fort accord inter-mod√®les pr√©dit la correction factuelle, tandis qu'une divergence significative signale soit une hallucination du mod√®le, soit une question insuffisamment sp√©cifi√©e. Nous √©valuons en outre trois strat√©gies de synth√®se - agr√©gation par vote majoritaire, s√©lection du centro√Øde s√©mantique et synth√®se LLM-as-Judge - par rapport aux r√©ponses de r√©f√©rence pr√©-enregistr√©es.

BMAS a des implications pratiques directes pour les d√©ploiements d'IA √† enjeux √©lev√©s dans les administrations publiques, les syst√®mes de sant√© et les syst√®mes juridiques, o√π aucune sortie de mod√®le unique ne peut √™tre inconditionnellement fiable. En traitant la **divergence comme un signal d'anomalie** plut√¥t que comme un √©chec de coordination, BMAS fournit une couche d'assurance qualit√© pratique pour les syst√®mes LLM en production.

**Mots-cl√©s :** grands mod√®les de langage, syst√®mes multi-agents, consensus, d√©tection des hallucinations, m√©thode Delphi, similarit√© s√©mantique, assurance qualit√© IA
