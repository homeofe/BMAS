# üìö 2. Travaux connexes

BMAS s'appuie sur des m√©thodes de consensus expert structur√©, des techniques LLM multi-√©chantillons et multi-mod√®les, des m√©triques d'√©valuation automatis√©e et le clustering bas√© sur la densit√©. Cette section examine chacun de ces domaines et clarifie le positionnement de BMAS par rapport aux travaux ant√©rieurs.

## 2.1 La m√©thode Delphi

Dalkey et Helmer (1963) ont introduit la m√©thode Delphi √† la RAND Corporation comme approche structur√©e de pr√©vision d'experts. Dans le protocole original, un panel d'experts fournissait des estimations ind√©pendantes sans conna√Ætre les r√©ponses des autres, et un facilitateur agr√©geait les r√©sultats sur plusieurs tours it√©ratifs. La force centrale de la m√©thode √©tait que l'isolation pr√©venait l'ancrage et la pens√©e de groupe, permettant aux d√©saccords genuins de se manifester avant que le consensus soit recherch√©. BMAS emprunte ce principe d'isolation directement : chaque LLM r√©pond aux prompts sans observer les sorties d'aucun autre mod√®le, garantissant que la convergence, lorsqu'elle se produit, refl√®te un raisonnement ind√©pendant plut√¥t que de l'imitation.

## 2.2 Self-Consistency

Wang et al. (2022) ont propos√© la self-consistency comme strat√©gie de d√©codage qui √©chantillonne plusieurs cha√Ænes de raisonnement √† partir d'un seul mod√®le de langage et s√©lectionne la r√©ponse finale par vote majoritaire. Cette m√©thode a d√©montr√© des am√©liorations significatives sur les benchmarks de raisonnement arithm√©tique et de bon sens en exploitant l'intuition que les chemins de raisonnement corrects convergent plus probablement vers la m√™me r√©ponse que les chemins incorrects. Cependant, comme toutes les cha√Ænes de raisonnement proviennent du m√™me mod√®le, la self-consistency ne capture que la variance de d√©codage intra-mod√®le, pas les diff√©rences plus profondes en donn√©es d'entra√Ænement, architecture et alignement qui distinguent des fournisseurs s√©par√©s. BMAS √©tend l'intuition de convergence-comme-signal-de-qualit√© au cadre inter-fournisseurs, o√π l'accord entre des mod√®les entra√Æn√©s ind√©pendamment constitue un a priori plus fort pour la correction.

## 2.3 Mixture of Agents

Wang et al. (2024) ont introduit le cadre Mixture-of-Agents (MoA), dans lequel plusieurs LLMs participent √† des tours d'agr√©gation it√©ratifs o√π chaque mod√®le peut observer et affiner les sorties des autres. MoA a d√©montr√© que le raffinement collaboratif entre mod√®les am√©liorait les performances sur des benchmarks tels qu'AlpacaEval et MT-Bench, atteignant des scores comparables aux mod√®les frontier. La diff√©rence critique avec BMAS est que MoA n'est pas aveugle : les mod√®les dans les tours ult√©rieurs sont expos√©s aux sorties pr√©c√©dentes, ce qui introduit le risque de propagation d'erreurs - une hallucination confiante dans un tour pr√©coce peut ancrer les mod√®les suivants et supprimer la dissidence l√©gitime. BMAS √©vite d√©lib√©r√©ment cela en imposant une isolation stricte tout au long de la phase de r√©ponse et en diff√©rant toute interaction inter-mod√®les √† une phase de synth√®se s√©par√©e.

## 2.4 LLM-as-Judge

Zheng et al. (2023) ont √©tudi√© l'utilisation de grands mod√®les de langage comme √©valuateurs des sorties d'autres mod√®les, introduisant les benchmarks MT-Bench et Chatbot Arena. Leur travail a montr√© que des LLMs puissants pouvaient servir de proxys √©volutifs pour l'√©valuation humaine, atteignant un fort accord avec des annotateurs experts sur des jugements de pr√©f√©rence par paires. Dans BMAS, en revanche, le r√¥le de juge est limit√© √† l'une des trois strat√©gies de synth√®se (S3) : un treizi√®me mod√®le synth√©tise les douze r√©ponses aveugles en une seule sortie, mais la correction est finalement mesur√©e par rapport √† des r√©ponses de r√©f√©rence pr√©-enregistr√©es, et non par rapport aux pr√©f√©rences du juge.

## 2.5 BERTScore

Zhang et al. (2020) ont propos√© BERTScore, une m√©trique d'√©valuation automatique qui calcule la similarit√© au niveau des tokens entre des textes candidats et de r√©f√©rence en utilisant des embeddings contextuels de mod√®les de transformers pr√©entra√Æn√©s. Contrairement aux m√©triques de chevauchement de n-grammes comme BLEU ou ROUGE, BERTScore capture l'√©quivalence s√©mantique √† travers diff√©rentes formes de surface et est robuste √† la paraphrase. BMAS adopte BERTScore F1 comme m√©trique de similarit√© par paires principale pour mesurer la convergence inter-mod√®les, compl√©t√©e par la similarit√© cosinus sur les embeddings au niveau des phrases pour l'efficacit√© computationnelle.

## 2.6 Constitutional AI

Bai et al. (2022) ont introduit Constitutional AI (CAI) chez Anthropic, une m√©thodologie d'entra√Ænement dans laquelle un mod√®le critique et r√©vise ses propres sorties selon un ensemble de principes (une "constitution") avant l'apprentissage par renforcement √† partir de retours humains. CAI a d√©montr√© que l'auto-critique pouvait r√©duire les sorties nuisibles tout en maintenant l'utilit√©, repr√©sentant une approche mono-mod√®le pour l'am√©lioration de la qualit√© par raffinement it√©ratif. BMAS peut √™tre vu comme √©tendant l'intuition critique-et-r√©vision d'une boucle mono-mod√®le √† un cadre multi-mod√®les et multi-fournisseurs : plut√¥t qu'un mod√®le se jugeant lui-m√™me, plusieurs mod√®les entra√Æn√©s ind√©pendamment servent de critiques implicites les uns des autres √† travers le signal de divergence.

## 2.7 DBSCAN

Ester et al. (1996) ont propos√© DBSCAN (Density-Based Spatial Clustering of Applications with Noise), un algorithme de clustering qui regroupe des points de donn√©es bas√© sur la connectivit√© de densit√© et identifie les points dans des r√©gions de faible densit√© comme du bruit ou des valeurs aberrantes. Contrairement au k-means, DBSCAN ne n√©cessite pas de sp√©cifier le nombre de clusters a priori et g√®re naturellement les clusters de forme irr√©guli√®re. BMAS emploie DBSCAN sur l'espace d'embedding des r√©ponses des mod√®les pour d√©tecter les sorties aberrantes : dans les domaines factuels, une r√©ponse aberrante - celle qui tombe en dehors du voisinage epsilon du cluster de consensus - est trait√©e comme une hallucination candidate, tandis que dans les domaines strat√©giques, les valeurs aberrantes peuvent repr√©senter des points de vue minoritaires l√©gitimes.

## 2.8 Positionnement

BMAS est, √† notre connaissance, le premier cadre √† combiner quatre propri√©t√©s absentes de tout approche ant√©rieure unique. Premi√®rement, il impose une isolation aveugle inter-fournisseurs : contrairement √† la self-consistency, qui √©chantillonne d'un seul mod√®le, BMAS collecte des r√©ponses de mod√®les entra√Æn√©s ind√©pendamment chez diff√©rents fournisseurs, capturant la variation en donn√©es d'entra√Ænement, architecture et alignement plut√¥t que la simple stochasticit√© de d√©codage. Deuxi√®mement, il introduit une analyse stratifi√©e par domaine, partitionnant les prompts en strates factuelle, r√©glementaire et strat√©gique pour tester si les patterns de convergence sont d√©pendants du domaine - une dimension non explor√©e par MoA ou les √©valuations LLM-as-Judge. Troisi√®mement, il traite la divergence comme un signal d'anomalie plut√¥t que comme un √©chec de coordination : un d√©saccord inter-mod√®les √©lev√© dans des domaines bien contraints est hypoth√©tis√© comme pr√©dicteur d'erreur factuelle, transformant le d√©saccord d'une nuisance en un outil de diagnostic. Quatri√®mement, il fournit une comparaison contr√¥l√©e des strat√©gies de synth√®se (vote majoritaire, centro√Øde s√©mantique et LLM-as-Judge) √©valu√©es par rapport √† des r√©ponses de r√©f√©rence pr√©-enregistr√©es, offrant des orientations empiriques sur la meilleure fa√ßon d'agr√©ger les sorties de mod√®les ind√©pendants en pratique.
