# 2. Travaux connexes

BMAS s'appuie sur des méthodes de consensus expert structuré, des techniques LLM multi-échantillons et multi-modèles, des métriques d'évaluation automatisée et le clustering basé sur la densité. Cette section examine chacun de ces domaines et clarifie le positionnement de BMAS par rapport aux travaux antérieurs.

## 2.1 La méthode Delphi

Dalkey et Helmer (1963) ont introduit la méthode Delphi à la RAND Corporation comme approche structurée de prévision d'experts. Dans le protocole original, un panel d'experts fournissait des estimations indépendantes sans connaître les réponses des autres, et un facilitateur agrégeait les résultats sur plusieurs tours itératifs. La force centrale de la méthode était que l'isolation prévenait l'ancrage et la pensée de groupe, permettant aux désaccords genuins de se manifester avant que le consensus soit recherché. BMAS emprunte ce principe d'isolation directement : chaque LLM répond aux prompts sans observer les sorties d'aucun autre modèle, garantissant que la convergence, lorsqu'elle se produit, reflète un raisonnement indépendant plutôt que de l'imitation.

## 2.2 Self-Consistency

Wang et al. (2022) ont proposé la self-consistency comme stratégie de décodage qui échantillonne plusieurs chaînes de raisonnement à partir d'un seul modèle de langage et sélectionne la réponse finale par vote majoritaire. Cette méthode a démontré des améliorations significatives sur les benchmarks de raisonnement arithmétique et de bon sens en exploitant l'intuition que les chemins de raisonnement corrects convergent plus probablement vers la même réponse que les chemins incorrects. Cependant, comme toutes les chaînes de raisonnement proviennent du même modèle, la self-consistency ne capture que la variance de décodage intra-modèle, pas les différences plus profondes en données d'entraînement, architecture et alignement qui distinguent des fournisseurs séparés. BMAS étend l'intuition de convergence-comme-signal-de-qualité au cadre inter-fournisseurs, où l'accord entre des modèles entraînés indépendamment constitue un a priori plus fort pour la correction.

## 2.3 Mixture of Agents

Wang et al. (2024) ont introduit le cadre Mixture-of-Agents (MoA), dans lequel plusieurs LLMs participent à des tours d'agrégation itératifs où chaque modèle peut observer et affiner les sorties des autres. MoA a démontré que le raffinement collaboratif entre modèles améliorait les performances sur des benchmarks tels qu'AlpacaEval et MT-Bench, atteignant des scores comparables aux modèles frontier. La différence critique avec BMAS est que MoA n'est pas aveugle : les modèles dans les tours ultérieurs sont exposés aux sorties précédentes, ce qui introduit le risque de propagation d'erreurs - une hallucination confiante dans un tour précoce peut ancrer les modèles suivants et supprimer la dissidence légitime. BMAS évite délibérément cela en imposant une isolation stricte tout au long de la phase de réponse et en différant toute interaction inter-modèles à une phase de synthèse séparée.

## 2.4 LLM-as-Judge

Zheng et al. (2023) ont étudié l'utilisation de grands modèles de langage comme évaluateurs des sorties d'autres modèles, introduisant les benchmarks MT-Bench et Chatbot Arena. Leur travail a montré que des LLMs puissants pouvaient servir de proxys évolutifs pour l'évaluation humaine, atteignant un fort accord avec des annotateurs experts sur des jugements de préférence par paires. Dans BMAS, en revanche, le rôle de juge est limité à l'une des trois stratégies de synthèse (S3) : un sixième modèle synthétise les cinq réponses aveugles en une seule sortie, mais la correction est finalement mesurée par rapport à des réponses de référence pré-enregistrées, et non par rapport aux préférences du juge.

## 2.5 BERTScore

Zhang et al. (2020) ont proposé BERTScore, une métrique d'évaluation automatique qui calcule la similarité au niveau des tokens entre des textes candidats et de référence en utilisant des embeddings contextuels de modèles de transformers préentraînés. Contrairement aux métriques de chevauchement de n-grammes comme BLEU ou ROUGE, BERTScore capture l'équivalence sémantique à travers différentes formes de surface et est robuste à la paraphrase. BMAS adopte BERTScore F1 comme métrique de similarité par paires principale pour mesurer la convergence inter-modèles, complétée par la similarité cosinus sur les embeddings au niveau des phrases pour l'efficacité computationnelle.

## 2.6 Constitutional AI

Bai et al. (2022) ont introduit Constitutional AI (CAI) chez Anthropic, une méthodologie d'entraînement dans laquelle un modèle critique et révise ses propres sorties selon un ensemble de principes (une "constitution") avant l'apprentissage par renforcement à partir de retours humains. CAI a démontré que l'auto-critique pouvait réduire les sorties nuisibles tout en maintenant l'utilité, représentant une approche mono-modèle pour l'amélioration de la qualité par raffinement itératif. BMAS peut être vu comme étendant l'intuition critique-et-révision d'une boucle mono-modèle à un cadre multi-modèles et multi-fournisseurs : plutôt qu'un modèle se jugeant lui-même, plusieurs modèles entraînés indépendamment servent de critiques implicites les uns des autres à travers le signal de divergence.

## 2.7 DBSCAN

Ester et al. (1996) ont proposé DBSCAN (Density-Based Spatial Clustering of Applications with Noise), un algorithme de clustering qui regroupe des points de données basé sur la connectivité de densité et identifie les points dans des régions de faible densité comme du bruit ou des valeurs aberrantes. Contrairement au k-means, DBSCAN ne nécessite pas de spécifier le nombre de clusters a priori et gère naturellement les clusters de forme irrégulière. BMAS emploie DBSCAN sur l'espace d'embedding des réponses des modèles pour détecter les sorties aberrantes : dans les domaines factuels, une réponse aberrante - celle qui tombe en dehors du voisinage epsilon du cluster de consensus - est traitée comme une hallucination candidate, tandis que dans les domaines stratégiques, les valeurs aberrantes peuvent représenter des points de vue minoritaires légitimes.

## 2.8 Positionnement

BMAS est, à notre connaissance, le premier cadre à combiner quatre propriétés absentes de tout approche antérieure unique. Premièrement, il impose une isolation aveugle inter-fournisseurs : contrairement à la self-consistency, qui échantillonne d'un seul modèle, BMAS collecte des réponses de modèles entraînés indépendamment chez différents fournisseurs, capturant la variation en données d'entraînement, architecture et alignement plutôt que la simple stochasticité de décodage. Deuxièmement, il introduit une analyse stratifiée par domaine, partitionnant les prompts en strates factuelle, réglementaire et stratégique pour tester si les patterns de convergence sont dépendants du domaine - une dimension non explorée par MoA ou les évaluations LLM-as-Judge. Troisièmement, il traite la divergence comme un signal d'anomalie plutôt que comme un échec de coordination : un désaccord inter-modèles élevé dans des domaines bien contraints est hypothétisé comme prédicteur d'erreur factuelle, transformant le désaccord d'une nuisance en un outil de diagnostic. Quatrièmement, il fournit une comparaison contrôlée des stratégies de synthèse (vote majoritaire, centroïde sémantique et LLM-as-Judge) évaluées par rapport à des réponses de référence pré-enregistrées, offrant des orientations empiriques sur la meilleure façon d'agréger les sorties de modèles indépendants en pratique.
