# üìù 1. Introduction

Les grands mod√®les de langage sont d√©sormais suffisamment performants pour √™tre d√©ploy√©s dans des domaines o√π la pr√©cision n'est pas optionnelle : analyse juridique, diagnostic m√©dical, conformit√© r√©glementaire et syst√®mes d'identit√© gouvernementaux. Dans ces domaines, une r√©ponse confiante mais erron√©e d'un mod√®le unique n'est pas un inconv√©nient mineur - c'est un √©chec aux cons√©quences r√©elles.

L'approche dominante pour am√©liorer la fiabilit√© des LLMs est soit un meilleur entra√Ænement (RLHF, Constitutional AI), soit un meilleur prompting (cha√Æne de pens√©e, augmentation par r√©cup√©ration). Les deux op√®rent dans un paradigme √† mod√®le unique : un mod√®le, une sortie, une r√©ponse √† faire confiance ou non.

Ce travail prend une approche diff√©rente. Au lieu de demander "comment rendre un mod√®le plus fiable ?", nous demandons : **que peut-on apprendre du d√©saccord entre plusieurs mod√®les qui ne peuvent pas s'influencer mutuellement ?**

## 1.1 L'insight fondamental

Lorsque cinq experts ind√©pendants r√©pondent √† la m√™me question sans se consulter, et que quatre d'entre eux donnent la m√™me r√©ponse tandis qu'un seul donne une r√©ponse diff√©rente, nous ne concluons pas que les quatre ont tort. Nous examinons la r√©ponse dissidente plus attentivement, mais nous faisons confiance au consensus comme a priori.

C'est la m√©thode Delphi, utilis√©e depuis 1963 pour la pr√©vision d'experts. Sa force est structurelle : **l'isolation pr√©vient la pens√©e de groupe ; le consensus √©merge d'un raisonnement ind√©pendant, non de la pression sociale.**

BMAS applique cette logique aux LLMs. Chaque mod√®le est un expert avec une distribution d'entra√Ænement particuli√®re, une date limite de connaissance et un ensemble de biais. Lorsqu'ils sont isol√©s les uns des autres et soumis √† la m√™me question, leur convergence ou divergence est elle-m√™me informative.

## 1.2 Ce qui est nouveau

Plusieurs travaux ant√©rieurs sont apparent√©s mais distincts :

**Self-Consistency** (Wang et al., 2022) g√©n√®re plusieurs cha√Ænes de raisonnement √† partir d'un *seul* mod√®le et utilise le vote majoritaire. BMAS utilise des mod√®les *diff√©rents* - ceci teste √† travers les distributions d'entra√Ænement, pas seulement la variance de d√©codage.

**Mixture of Agents** (Wang et al., 2024) permet aux mod√®les de voir les sorties des autres lors de tours d'agr√©gation. Cela produit un raffinement collaboratif, mais introduit le risque de propagation des erreurs : si un mod√®le produit une hallucination confiante au premier tour, les mod√®les suivants peuvent s'y ancrer.

**LLM-as-Judge** (Zheng et al., 2023) utilise un mod√®le pour √©valuer un autre. BMAS utilise un mod√®le pour *synth√©tiser* les sorties de plusieurs autres - le r√¥le de juge est limit√© √† la phase de synth√®se finale.

BMAS est le premier cadre √† combiner quatre propri√©t√©s :
1. Isolation aveugle stricte (aucune contamination crois√©e)
2. Diversit√© des mod√®les (fournisseurs, architectures, distributions d'entra√Ænement diff√©rents)
3. Analyse stratifi√©e par domaine (factuel, r√©glementaire, strat√©gique)
4. Divergence comme signal (non comme √©chec)

## 1.3 Motivation pratique

Cette recherche est n√©e d'une exp√©rience op√©rationnelle dans la construction d'AEGIS, un syst√®me de v√©rification d'identit√© gouvernementale transfrontalier de l'UE, et d'AAHP (AI-to-AI Handoff Protocol), un cadre structur√© d'orchestration multi-agents. Dans ces deux syst√®mes, des pipelines multi-agents sont utilis√©s pour des d√©cisions d'architecture, des analyses de conformit√© et des revues d'impl√©mentation.

Une question pratique s'est pos√©e : lorsque plusieurs LLMs sont utilis√©s comme examinateurs ind√©pendants dans un pipeline, dans quelle mesure leurs sorties diff√®rent-elles r√©ellement ? Et lorsqu'ils diff√®rent, qui a raison ?

BMAS est la r√©ponse formelle √† cette question.

## 1.4 Contributions

Ce travail apporte les contributions suivantes :

1. **M√©thodologie BMAS :** Un protocole formalis√© de synth√®se multi-agents aveugle avec contraintes d'isolation, suite de m√©triques et strat√©gies de synth√®se.
2. **Etude empirique :** R√©sultats de 45 prompts sur 12 LLMs dans 3 strates de domaines, avec des r√©ponses de r√©f√©rence pr√©-enregistr√©es pour les domaines A et B.
3. **Validation de l'hypoth√®se divergence-comme-signal :** Donn√©es statistiques montrant que la divergence inter-mod√®les pr√©dit le taux d'erreur factuelle.
4. **Comparaison des strat√©gies de synth√®se :** Evaluation empirique du vote majoritaire, du centro√Øde s√©mantique et de la synth√®se LLM-as-Judge par rapport aux r√©ponses de r√©f√©rence.
5. **Jeu de donn√©es ouvert :** Tous les prompts, les sorties brutes des mod√®les et les scores de m√©triques sont publi√©s en tant que benchmark public.

## 1.5 Structure du document

La section 2 examine les travaux connexes. La section 3 d√©crit la m√©thodologie BMAS et le design exp√©rimental. La section 4 pr√©sente les r√©sultats. La section 5 analyse la corr√©lation divergence-hallucination. La section 6 √©value les strat√©gies de synth√®se. La section 7 discute des implications, des limites et des travaux futurs. La section 8 conclut.
