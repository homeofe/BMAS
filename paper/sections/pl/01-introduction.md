#  1. Wprowadzenie

Du偶e modele jzykowe osigny poziom mo偶liwoci wystarczajcy do wdra偶ania w domenach, gdzie dokadno nie jest opcjonalna: analiza prawna, diagnostyka medyczna, zgodno regulacyjna oraz rzdowe systemy identyfikacji. W tych obszarach pewna, lecz bdna odpowied藕 pojedynczego modelu nie jest drobn niedogodnoci - jest niepowodzeniem o realnych konsekwencjach.

Dominujce podejcie do poprawy niezawodnoci LLM to albo lepsze szkolenie (RLHF, Constitutional AI), albo lepsze promptowanie (acuch mylenia, rozszerzanie przez pobieranie). Oba dziaaj w paradygmacie jednego modelu: jeden model, jedna odpowied藕, jeden wynik, kt贸remu mo偶na lub nie mo偶na ufa.

Niniejsza praca przyjmuje inne podejcie. Zamiast pyta "jak sprawi, by jeden model by bardziej niezawodny", pytamy: **czego mo偶emy si nauczy z niezgodnoci midzy wieloma modelami, kt贸re nie mog wzajemnie na siebie wpywa?**

## 1.1 Centralna intuicja

Gdy pi niezale偶nych ekspert贸w odpowiada na to samo pytanie bez konsultowania si ze sob, a czterech z nich daje t sam odpowied藕, podczas gdy jeden daje odmienn, nie wycigamy wniosku, 偶e ci czterej si myl. Dokadniej badamy odpowied藕 odmiennego eksperta, ale ufamy konsensusowi jako punktowi wyjcia.

To jest metoda Delphi, stosowana od 1963 roku w prognozowaniu eksperckim. Jej sia ma charakter strukturalny: **izolacja zapobiega myleniu grupowemu; konsensus wynika z niezale偶nego rozumowania, nie z presji spoecznej.**

BMAS stosuje t logik do LLM. Ka偶dy model jest ekspertem z okrelonym rozkadem danych treningowych, horyzontem wiedzy i zestawem uprzedze. Gdy zostan od siebie odizolowane i otrzymaj to samo pytanie, ich konwergencja lub dywergencja jest sama w sobie informacyjna.

## 1.2 Co jest nowego

Kilka wczeniejszych prac jest pokrewnych, ale zasadniczo r贸偶nych:

**Self-Consistency** (Wang et al., 2022) generuje wiele acuch贸w rozumowania z *jednego* modelu i stosuje gosowanie wikszociowe. BMAS u偶ywa *r贸偶nych* modeli - testuje to r贸偶nice w rozkadach treningowych, a nie tylko wariancj dekodowania.

**Mixture of Agents** (Wang et al., 2024) pozwala modelom widzie wyniki innych w rundach agregacji. Daje to wsp贸pracujce doskonalenie, lecz wprowadza ryzyko propagacji bd贸w: jeli model w pierwszej rundzie wytworzy pewn halucynacj, kolejne modele mog si na niej zakotwicy.

**LLM-as-Judge** (Zheng et al., 2023) u偶ywa jednego modelu do oceny innego. BMAS u偶ywa jednego modelu do *syntezy* wynik贸w kilku innych - rola sdziego jest ograniczona do kocowej fazy syntezy.

BMAS jest pierwszym frameworkiem czcym cztery waciwoci:
1. cisa lepa izolacja (brak wzajemnej kontaminacji)
2. R贸偶norodno modeli (r贸偶ni dostawcy, architektury, rozkady treningowe)
3. Analiza uwarstwiona wedug dziedzin (faktyczna, regulacyjna, strategiczna)
4. Dywergencja jako sygna (nie jako niepowodzenie)

## 1.3 Praktyczna motywacja

Badanie wyniko z dowiadcze operacyjnych zdobytych podczas budowy systemu AEGIS - transgranicznego systemu weryfikacji to偶samoci rzdowej UE (obejmujcego m.in. cze dla Polski) - oraz AAHP (AI-to-AI Handoff Protocol), ustrukturyzowanego frameworku orkiestracji wieloagentowej. W obu systemach potoki wieloagentowe s u偶ywane do podejmowania decyzji architektonicznych, analizy zgodnoci i przegld贸w implementacji.

Pojawio si praktyczne pytanie: gdy wiele LLM jest u偶ywanych jako niezale偶ni recenzenci w potoku, jak bardzo r贸偶ni si ich wyniki? A gdy si r贸偶ni, kto ma racj?

BMAS jest formalnym odpowiedzeniem na to pytanie.

## 1.4 Wkad naukowy

Niniejsza praca wnosi nastpujcy wkad:

1. **Metodologia BMAS:** Sformalizowany protok贸 lepej syntezy wieloagentowej z ograniczeniami izolacji, zestawem metryk i strategiami syntezy.
2. **Badanie empiryczne:** Wyniki 45 prompt贸w dla 12 LLM w 3 warstwach dziedzinowych, z pre-rejestrowanymi odpowiedziami referencyjnymi dla dziedzin A i B.
3. **Walidacja hipotezy dywergencji-jako-sygnau:** Dowody statystyczne, 偶e dywergencja midzy modelami przewiduje wska藕nik bd贸w faktycznych.
4. **Por贸wnanie strategii syntezy:** Empiryczna ocena gosowania wikszociowego, centroidu semantycznego i syntezy LLM-as-Judge w odniesieniu do odpowiedzi referencyjnych.
5. **Otwarty zbi贸r danych:** Wszystkie prompty, surowe wyniki modeli i wska藕niki metryk opublikowane jako publiczny benchmark.

## 1.5 Struktura artykuu

Sekcja 2 omawia prace pokrewne. Sekcja 3 opisuje metodologi BMAS i projekt eksperymentu. Sekcja 4 przedstawia wyniki. Sekcja 5 analizuje korelacje dywergencja-halucynacja. Sekcja 6 ocenia strategie syntezy. Sekcja 7 omawia implikacje, ograniczenia i przysze prace. Sekcja 8 zawiera wnioski.
