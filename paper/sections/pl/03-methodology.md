#  3. Metodologia

## 3.1 Przegld protokou BMAS

Blind Multi-Agent Synthesis (BMAS) to czterofazowy protok贸 elicytacji, por贸wnania i syntezy odpowiedzi wielu LLM na identyczne zapytania:

1. **lepa elicytacja** - Ka偶dy model otrzymuje ten sam prompt bez wiedzy o badaniu, innych modelach ani innych odpowiedziach.
2. **Obliczanie metryk** - Parowe podobiestwo semantyczne, dokadno faktyczna i wykrywanie wartoci odstajcych s obliczane dla wszystkich odpowiedzi.
3. **Synteza** - Trzy strategie syntezy agreguj poszczeg贸lne odpowiedzi w jeden wynik.
4. **Ocena** - Wyniki syntezy s oceniane wzgldem pre-rejestrowanych odpowiedzi referencyjnych (dziedziny A i B) lub oceny eksperckiej (dziedzina C).

Protok贸 wymusza cis **zasad braku kontaminacji**: 偶adna odpowied藕 modelu nie jest udostpniana 偶adnemu innemu modelowi w 偶adnej fazie poprzedzajcej syntez.

## 3.2 Modele

Oceniamy dwanacie najbardziej zaawansowanych LLM od czterech r贸偶nych dostawc贸w:

| ID | Model | Dostawca | Okno kontekstu |
|---|---|---|---|
| M1 | claude-sonnet-4-6 | Anthropic | 1M token贸w |
| M2 | claude-opus-4-6 | Anthropic | 1M token贸w |
| M3 | gpt-5.3-codex | OpenAI | 272k token贸w |
| M4 | gemini-2.5-pro | Google | 1M token贸w |
| M5 | sonar-pro | Perplexity | 127k token贸w |

R贸偶norodno wielodostawcza jest celowa. Modele tego samego dostawcy dziel rodow贸d architektoniczny i potoki danych treningowych, co mo偶e redukowa dywergencj nawet w warunkach lepych.

**Implementacja izolacji:** Ka偶dy model dziaa w oddzielnej, izolowanej sesji bez wsp贸lnego kontekstu. Systemowy prompt jest identyczny we wszystkich modelach:

> *"Jeste kompetentnym asystentem eksperckim. Odpowiedz na nastpujce pytanie mo偶liwie najdokadniej i najwyczerpujcym sposobem. Bd藕 precyzyjny, oparty na faktach i ustrukturyzowany. Jeli nie jeste pewien konkretnego szczeg贸u, wyra藕 to wprost."*

Temperatura nie jest modyfikowana. Celowo zachowujemy domylne zachowanie pr贸bkowania ka偶dego modelu, aby uchwyci naturaln wariancj odpowiedzi.

## 3.3 Projektowanie prompt贸w

### 3.3.1 Struktura dziedzin

Konstruujemy 45 prompt贸w w trzech warstwach dziedzinowych:

**Dziedzina A - Techniczne wysokiej precyzji (A01-A10):** Pytania z obiektywnie prawidowymi odpowiedziami weryfikowalnymi wzgldem autorytatywnych 藕r贸de pierwotnych (standardy NIST FIPS, NVD, RFC IETF, specyfikacje OpenID Foundation). Przykady: uzasadnienie punktacji CVSS, rozmiary kluczy algorytm贸w PQC, wyliczenie zestaw贸w szyfr贸w TLS 1.3.

**Dziedzina B - Regulacyjna/Zgodno (B01-B10):** Pytania oparte na tekstach prawnych i regulacyjnych z autorytatywnymi 藕r贸dami (RODO, eIDAS 2.0, NIS2, ISO 27001, BSI C5). Centralne odpowiedzi s zdefiniowane w tekcie formalnym. Przykady: wyjtki od usuwania danych z Artykuu 17(3) RODO, klasyfikacje sektorowe NIS2, r贸偶nice poziom贸w oceny TISAX.

**Dziedzina C - Strategiczna/Nieokrelona (C01-C10):** Pytania bez jednej prawidowej odpowiedzi, wymagajce eksperckiego osdu i rozumowania architektonicznego. Istnieje wiele mo偶liwych do obronienia stanowisk. Przykady: decyzje architektoniczne zero-trust, priorytyzacja migracji PQC, kompromisy inwestycyjne w zgodnoci.

### 3.3.2 Wymagania wobec prompt贸w

Wszystkie prompty speniaj cztery kryteria:
1. **Samodzielne** - mo偶liwe do odpowiedzi bez zewntrznego kontekstu ani pobierania dokument贸w
2. **Ustrukturyzowana odpowied藕** - ka偶dy prompt okrela wymagany format wyjcia
3. **Ograniczona dugo** - oczekiwana odpowied藕 300-600 token贸w dla dziedzin A-B; 400-800 dla dziedziny C
4. **Weryfikowalne** - dla dziedzin A i B istnieje weryfikowalna odpowied藕

### 3.3.3 Pre-rejestracja

Zgodnie z najlepszymi praktykami otwartej nauki, odpowiedzi referencyjne dla dziedzin A i B zostay udokumentowane i zablokowane przed uruchomieniem jakiegokolwiek modelu. Zapobiega to niewiadomemu uprzedzeniu potwierdzenia w ocenianiu.

## 3.4 Metryki

### 3.4.1 Podobiestwo semantyczne (podstawowe)

Obliczamy parowe podobiestwo cosinusowe midzy embeddingami odpowiedzi za pomoc modelu sentence-transformer `all-mpnet-base-v2`. Dla N modeli daje to macierz podobiestwa N x N na prompt. Raportujemy:
- **rednie parowe podobiestwo (MPS):** rednia ze wszystkich N(N-1)/2 parowych wynik贸w
- **Minimalne parowe podobiestwo:** najbardziej rozbie偶na para
- **Odchylenie standardowe podobiestwa:** wariancja w obrbie klastra odpowiedzi na prompt

### 3.4.2 BERTScore

Obliczamy parowe BERTScore F1 jako wt贸rne miary podobiestwa semantycznego na poziomie token贸w. BERTScore rejestruje blisko leksykaln poza embeddingami na poziomie zda.

### 3.4.3 Jaccard na kluczowych twierdzeniach

Wyodrbniamy dyskretne twierdzenia faktyczne z ka偶dej odpowiedzi za pomoc segmentacji zda i obliczamy parowe podobiestwo Jaccarda na znormalizowanych zbiorach twierdzenia. Metryka ta rejestruje zgodno strukturaln.

### 3.4.4 Wykrywanie wartoci odstajcych

Stosujemy DBSCAN z eps=0.15 i min_samples=2. Modele, kt贸rych embeddingi wypadaj poza wszystkie klastry ssiedztwa, otrzymuj etykiet wartoci odstajcej (-1). Traktujemy status wartoci odstajcej jako sygna potencjalnej halucynacji w dziedzinach A i B.

### 3.4.5 Dokadno faktyczna (tylko dziedziny A i B)

Dla ka偶dej odpowiedzi dziedzin A i B oceniamy dokadno faktyczn wzgldem listy kontrolnej pre-rejestrowanych odpowiedzi referencyjnych. Wynik dokadnoci faktycznej to uamek spenionych element贸w listy.

## 3.5 Strategie syntezy

**S1 - Gosowanie wikszociowe (poziom twierdzenia):** Twierdzenia faktyczne s akceptowane, jeli pojawiaj si w odpowiedziach co najmniej 60% modeli. Twierdzenia mniejszociowe s dodawane z markerem [MINORITY].

**S2 - Centroid semantyczny:** Odpowied藕, kt贸rej embedding jest najbli偶szy redniej wszystkich embedding贸w, jest wybierana jako baza syntezy. Nie dodaje si nowych treci.

**S3 - LLM-as-Judge:** Pi zanonimizowanych odpowiedzi jest przedstawianych sz贸stej instancji modelu (M2, claude-opus-4-6) z poleceniem produkcji jednej autorytatywnej syntezy, oznaczajc twierdzenia mniejszociowe ([MINORITY]) i sprzecznoci ([DISPUTED]).

## 3.6 Hipotezy

**H1 (Konwergencja w dziedzinach faktycznych):** rednie parowe podobiestwo semantyczne dla prompt贸w dziedzin A i B przekroczy 0.75 (BERTScore F1).

**H2 (Dywergencja sygnalizuje bd):** Wr贸d odpowiedzi dziedzin A i B modele odstajce (etykieta DBSCAN -1) bd miay znaczco ni偶sze wyniki dokadnoci faktycznej ni偶 modele nieodstajce (jednostronny test t, alfa=0.05).

**H3 (Wpyw dziedziny na konwergencj):** rednie parowe podobiestwo dla dziedziny C bdzie znaczco ni偶sze ni偶 dla dziedzin A i B (jednoczynnikowa ANOVA, Tukey HSD post-hoc, alfa=0.05).

## 3.7 Konfiguracja eksperymentalna

Wszystkie uruchomienia modeli zostay wykonane za porednictwem bramy OpenClaw, kt贸ra kieruje niezale偶nie do API ka偶dego dostawcy. Kompletny zbi贸r danych 540 uruchomie (45 prompt贸w x 5 modeli) jest publikowany razem z niniejsz prac.
