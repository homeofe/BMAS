#  Streszczenie

Przedstawiamy **Blind Multi-Agent Synthesis (BMAS)**, metodologi pomiaru konwergencji i dywergencji wielu du偶ych modeli jzykowych (LLM) odpowiadajcych na identyczne zapytania w cisej izolacji. Inspirowany metod Delphi stosowan w prognozowaniu eksperckim, BMAS wymusza pen izolacj odpowiedzi na poziomie modelu: 偶aden model nie obserwuje wynik贸w innego modelu przed faz syntezy.

Oceniamy dwanacie najbardziej zaawansowanych LLM na trzech poziomach dziedzinowych: (A) pytania techniczne wysokiej precyzji z weryfikowalnymi odpowiedziami, (B) pytania regulacyjne i dotyczce zgodnoci z autorytatywnymi 藕r贸dami prawnymi oraz (C) pytania strategiczne i architektoniczne z uzasadnionymi rozbie偶nociami midzy ekspertami. Stosujc metryki podobiestwa semantycznego (BERTScore, odlego cosinusowa na embeddingach), dokadno faktyczn w por贸wnaniu z pre-rejestrowanymi odpowiedziami referencyjnymi oraz wykrywanie wartoci odstajcych za pomoc klasteryzacji DBSCAN, kwantyfikujemy odchylenia midzy modelami i ich zwizek z typem dziedziny oraz wska藕nikiem halucynacji.

Nasza centralna hipoteza gosi, 偶e w dobrze zdefiniowanych dziedzinach faktycznych odpowiedzi LLM konwerguj w stopniu umo偶liwiajcym traktowanie **konsensusu jako sygnau jakoci**: wysoka zgodno midzy modelami przewiduje poprawno faktyczn, natomiast znaczca dywergencja sygnalizuje halucynacj modelu lub niewystarczajco sprecyzowane pytanie. Oceniamy ponadto trzy strategie syntezy - agregacj przez gosowanie wikszociowe, wyb贸r centroidu semantycznego oraz syntez LLM-as-Judge - w odniesieniu do pre-rejestrowanych odpowiedzi referencyjnych.

BMAS ma bezporednie implikacje praktyczne dla wdro偶e AI wysokiego ryzyka w administracji publicznej, systemach ochrony zdrowia i systemach prawnych, gdzie 偶adnemu pojedynczemu modelowi nie mo偶na bezwarunkowo ufa. Traktujc **dywergencj jako sygna anomalii** zamiast niepowodzenia koordynacji, BMAS dostarcza praktyczn warstw zapewnienia jakoci dla system贸w LLM w rodowisku produkcyjnym.

**Sowa kluczowe:** du偶e modele jzykowe, systemy wieloagentowe, konsensus, wykrywanie halucynacji, metoda Delphi, podobiestwo semantyczne, zapewnienie jakoci AI
