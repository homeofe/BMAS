# üìã Resumen

Presentamos **Blind Multi-Agent Synthesis (BMAS)**, una metodolog√≠a para medir la convergencia y divergencia de m√∫ltiples modelos de lenguaje grande (LLMs) que responden a prompts id√©nticos en estricto aislamiento. Inspirado en el m√©todo Delphi de la predicci√≥n experta, BMAS impone un aislamiento completo de las respuestas por modelo: ning√∫n modelo observa la salida de otro modelo antes de la fase de s√≠ntesis.

Evaluamos doce LLMs de √∫ltima generaci√≥n en tres estratos de dominio: (A) preguntas t√©cnicas de alta precisi√≥n con respuestas verificables, (B) preguntas regulatorias y de cumplimiento con fuentes jur√≠dicas autorizadas, y (C) preguntas estrat√©gicas y arquitect√≥nicas con desacuerdos leg√≠timos entre expertos. Mediante m√©tricas de similitud sem√°ntica (BERTScore, distancia coseno sobre embeddings), precisi√≥n factual comparada con respuestas de referencia pre-registradas y detecci√≥n de valores at√≠picos mediante clustering DBSCAN, cuantificamos la desviaci√≥n entre modelos y su relaci√≥n con el tipo de dominio y la tasa de alucinaci√≥n.

Nuestra hip√≥tesis central es que en dominios factuales bien definidos, las respuestas de los LLMs convergen en tal medida que el **consenso sirve como se√±al de calidad**: un alto acuerdo entre modelos predice la correcci√≥n factual, mientras que una divergencia significativa se√±aliza alucinaciones del modelo o una pregunta insuficientemente especificada. Adem√°s, evaluamos tres estrategias de s√≠ntesis - agregaci√≥n por voto mayoritario, selecci√≥n del centroide sem√°ntico y s√≠ntesis LLM-as-Judge - frente a respuestas de referencia pre-registradas.

BMAS tiene implicaciones pr√°cticas directas para despliegues de IA de alto riesgo en administraciones p√∫blicas, sistemas de salud y sistemas jur√≠dicos, donde ninguna salida de un modelo √∫nico puede ser confiable incondicionalmente. Al tratar la **divergencia como se√±al de anomal√≠a** en lugar de un fallo de coordinaci√≥n, BMAS proporciona una capa pr√°ctica de aseguramiento de calidad para sistemas LLM en producci√≥n.

**Palabras clave:** modelos de lenguaje grande, sistemas multi-agente, consenso, detecci√≥n de alucinaciones, m√©todo Delphi, similitud sem√°ntica, aseguramiento de calidad IA
