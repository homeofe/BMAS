# Resumen

Presentamos **Blind Multi-Agent Synthesis (BMAS)**, una metodología para medir la convergencia y divergencia de múltiples modelos de lenguaje grande (LLMs) que responden a prompts idénticos en estricto aislamiento. Inspirado en el método Delphi de la predicción experta, BMAS impone un aislamiento completo de las respuestas por modelo: ningún modelo observa la salida de otro modelo antes de la fase de síntesis.

Evaluamos doce LLMs de última generación en tres estratos de dominio: (A) preguntas técnicas de alta precisión con respuestas verificables, (B) preguntas regulatorias y de cumplimiento con fuentes jurídicas autorizadas, y (C) preguntas estratégicas y arquitectónicas con desacuerdos legítimos entre expertos. Mediante métricas de similitud semántica (BERTScore, distancia coseno sobre embeddings), precisión factual comparada con respuestas de referencia pre-registradas y detección de valores atípicos mediante clustering DBSCAN, cuantificamos la desviación entre modelos y su relación con el tipo de dominio y la tasa de alucinación.

Nuestra hipótesis central es que en dominios factuales bien definidos, las respuestas de los LLMs convergen en tal medida que el **consenso sirve como señal de calidad**: un alto acuerdo entre modelos predice la corrección factual, mientras que una divergencia significativa señaliza alucinaciones del modelo o una pregunta insuficientemente especificada. Además, evaluamos tres estrategias de síntesis - agregación por voto mayoritario, selección del centroide semántico y síntesis LLM-as-Judge - frente a respuestas de referencia pre-registradas.

BMAS tiene implicaciones prácticas directas para despliegues de IA de alto riesgo en administraciones públicas, sistemas de salud y sistemas jurídicos, donde ninguna salida de un modelo único puede ser confiable incondicionalmente. Al tratar la **divergencia como señal de anomalía** en lugar de un fallo de coordinación, BMAS proporciona una capa práctica de aseguramiento de calidad para sistemas LLM en producción.

**Palabras clave:** modelos de lenguaje grande, sistemas multi-agente, consenso, detección de alucinaciones, método Delphi, similitud semántica, aseguramiento de calidad IA
