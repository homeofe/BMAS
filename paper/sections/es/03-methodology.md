# 游댧 3. Metodolog칤a

## 3.1 Descripci칩n general del protocolo BMAS

Blind Multi-Agent Synthesis (BMAS) es un protocolo de cuatro fases para elicitar, comparar y sintetizar respuestas de m칰ltiples LLMs sobre prompts id칠nticos:

1. **Elicitaci칩n ciega** - Cada modelo recibe el mismo prompt sin conocimiento del estudio, otros modelos u otras respuestas.
2. **C치lculo de m칠tricas** - Se calculan similitud sem치ntica por pares, precisi칩n factual y detecci칩n de valores at칤picos para todas las respuestas.
3. **S칤ntesis** - Tres estrategias de s칤ntesis agregan las respuestas individuales en una 칰nica salida.
4. **Evaluaci칩n** - Las salidas de s칤ntesis se punt칰an frente a respuestas de referencia pre-registradas (dominios A y B) o evaluaci칩n experta (dominio C).

El protocolo impone una estricta **regla de no contaminaci칩n**: ninguna respuesta de un modelo se pone a disposici칩n de otro modelo en ninguna fase anterior a la s칤ntesis.

## 3.2 Modelos

Evaluamos doce LLMs de cinco proveedores distintos:

| ID | Modelo | Proveedor | Ventana de contexto |
|---|---|---|---|
| M1 | claude-sonnet-4-6 | Anthropic | 1M tokens |
| M2 | claude-opus-4-6 | Anthropic | 1M tokens |
| M3 | gpt-5.3-codex | OpenAI | 272k tokens |
| M4 | gemini-2.5-pro | Google | 1M tokens |
| M5 | sonar-pro | Perplexity | 127k tokens |

La diversidad multi-proveedor es deliberada. Los modelos del mismo proveedor comparten linaje arquitect칩nico y pipelines de datos de entrenamiento, lo que puede reducir la divergencia incluso en condiciones ciegas.

**Implementaci칩n de aislamiento:** Cada modelo corre en una sesi칩n aislada separada sin contexto compartido. El system prompt es id칠ntico en todos los modelos:

> *"Eres un asistente experto con amplio conocimiento. Responde la siguiente pregunta con la mayor precisi칩n y exhaustividad posible. S칠 preciso, factual y estructurado. Si no est치s seguro de alg칰n detalle espec칤fico, ind칤calo expl칤citamente."*

La temperatura no se modifica. Preservamos deliberadamente el comportamiento de muestreo predeterminado de cada modelo para capturar la varianza natural de respuestas.

## 3.3 Dise침o de prompts

### 3.3.1 Estructura de dominios

Construimos 45 prompts en tres estratos de dominio:

**Dominio A - T칠cnico de alta precisi칩n (A01-A10):** Preguntas con respuestas objetivamente correctas verificables frente a fuentes primarias autorizadas (est치ndares NIST FIPS, NVD, RFCs IETF, especificaciones OpenID Foundation). Ejemplos: justificaci칩n de puntuaci칩n CVSS, tama침os de clave de algoritmos PQC, enumeraci칩n de cipher suites TLS 1.3.

**Dominio B - Regulatorio/Cumplimiento (B01-B10):** Preguntas basadas en texto legal y regulatorio con fuentes autorizadas (RGPD, eIDAS 2.0, NIS2, ISO 27001, BSI C5). Las respuestas centrales est치n definidas en texto formal. Ejemplos: excepciones de borrado del Art칤culo 17(3) del RGPD, clasificaciones sectoriales de NIS2, diferencias de nivel de evaluaci칩n TISAX.

**Dominio C - Estrat칠gico/Ambiguo (C01-C10):** Preguntas sin respuesta 칰nica correcta que requieren juicio experto y razonamiento arquitect칩nico. Existen m칰ltiples posiciones defendibles. Ejemplos: decisiones de arquitectura zero-trust, priorizaci칩n de migraci칩n PQC, compensaciones de inversi칩n en cumplimiento.

### 3.3.2 Requisitos de los prompts

Todos los prompts satisfacen cuatro criterios:
1. **Aut칩nomos** - respondibles sin contexto externo ni recuperaci칩n de documentos
2. **Respuesta estructurada** - cada prompt especifica el formato de salida requerido
3. **Longitud acotada** - respuesta esperada de 300-600 tokens para dominios A-B; 400-800 para dominio C
4. **Verificables** - para los dominios A y B existe una respuesta verificable

### 3.3.3 Pre-registro

Siguiendo las mejores pr치cticas de ciencia abierta, las respuestas de referencia para los dominios A y B fueron documentadas y bloqueadas antes de cualquier ejecuci칩n de modelos. Esto evita el sesgo de confirmaci칩n inconsciente en la puntuaci칩n.

## 3.4 M칠tricas

### 3.4.1 Similitud sem치ntica (primaria)

Calculamos la similitud coseno por pares entre embeddings de respuestas usando el modelo sentence-transformer `all-mpnet-base-v2`. Para N modelos, esto produce una matriz de similitud N x N por prompt. Reportamos:
- **Similitud por pares media (MPS):** media de todos los N(N-1)/2 scores por pares
- **Similitud m칤nima por pares:** el par m치s divergente
- **Desviaci칩n est치ndar de similitud:** varianza dentro del cluster de respuestas del prompt

### 3.4.2 BERTScore

Calculamos BERTScore F1 por pares como medida secundaria de similitud sem치ntica a nivel de token. BERTScore captura la proximidad l칠xica m치s all치 de los embeddings a nivel de oraci칩n.

### 3.4.3 Jaccard sobre afirmaciones clave

Extraemos afirmaciones factuales discretas de cada respuesta mediante segmentaci칩n de oraciones y calculamos la similitud Jaccard por pares sobre conjuntos de afirmaciones normalizados. Esta m칠trica captura el acuerdo estructural.

### 3.4.4 Detecci칩n de valores at칤picos

Aplicamos DBSCAN con eps=0.15 y min_samples=2. Los modelos cuyos embeddings caen fuera de todos los clusters de vecindario reciben una etiqueta de valor at칤pico (-1). Tratamos el estado de valor at칤pico como se침al de alucinaci칩n potencial en los dominios A y B.

### 3.4.5 Precisi칩n factual (solo dominios A y B)

Para cada respuesta de los dominios A y B, puntuamos la precisi칩n factual frente a la lista de verificaci칩n de respuestas de referencia pre-registradas. La puntuaci칩n de precisi칩n factual es la fracci칩n de elementos satisfechos.

## 3.5 Estrategias de s칤ntesis

**S1 - Voto mayoritario (nivel de afirmaci칩n):** Las afirmaciones factuales se aceptan si aparecen en respuestas de al menos el 60% de los modelos. Las afirmaciones minoritarias se a침aden con un marcador [MINORITY].

**S2 - Centroide sem치ntico:** La respuesta cuyo embedding es m치s cercano a la media de todos los embeddings se selecciona como base de s칤ntesis. No se a침ade nuevo contenido.

**S3 - LLM-as-Judge:** Las doce respuestas anonimizadas se presentan a una sexta instancia de modelo (M2, claude-opus-4-6) con instrucci칩n de producir una s칤ntesis autoritativa 칰nica, marcando afirmaciones minoritarias ([MINORITY]) y contradicciones ([DISPUTED]).

## 3.6 Hip칩tesis

**H1 (Convergencia en dominios factuales):** La similitud sem치ntica por pares media para los prompts de los dominios A y B superar치 0.75 (BERTScore F1).

**H2 (La divergencia se침aliza error):** Entre las respuestas de los dominios A y B, los modelos at칤picos (etiqueta DBSCAN -1) tendr치n puntuaciones de precisi칩n factual significativamente m치s bajas que los modelos no at칤picos (t-test unilateral, alfa=0.05).

**H3 (Efecto del dominio sobre la convergencia):** La similitud por pares media para el dominio C ser치 significativamente menor que para los dominios A y B (ANOVA unidireccional, Tukey HSD post-hoc, alfa=0.05).

## 3.7 Configuraci칩n experimental

Todas las ejecuciones de modelos se ejecutaron a trav칠s del gateway de OpenClaw, que enruta de forma independiente a la API de cada proveedor. El dataset completo de 540 ejecuciones (45 prompts x 5 modelos) se publica junto con este art칤culo.
